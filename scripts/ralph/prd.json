{
  "branchName": "feature/codebase-health",
  "userStories": [
    {
      "id": "US-001",
      "title": "Add inference lock to detectors",
      "priority": 1,
      "passes": true,
      "description": "Add a threading.Lock to BaseDetector that serializes inference calls. Each detector instance must acquire the lock in detect() to prevent concurrent PyTorch inference, which is not thread-safe.",
      "acceptanceCriteria": [
        "BaseDetector.__init__ creates self._inference_lock = threading.Lock()",
        "BaseDetector gets a thread-safe detect_safe() method or detect() itself acquires the lock",
        "FaceBiSeNetDetector.detect() acquires self._inference_lock before any model inference",
        "YOLOv8SegDetector.detect() acquires self._inference_lock before any model inference",
        "Lock is acquired/released via 'with' statement (context manager), not manual acquire/release",
        "Quality check: python -m py_compile server/detectors/base.py && python -m py_compile server/detectors/face_bisenet.py && python -m py_compile server/detectors/yolov8_seg.py"
      ],
      "notes": "The lock goes on the detector instance, NOT on AppState. state.detector_lock protects detector creation; this new lock protects detector usage. Do not change the detect() signature or return type. BaseDetector is an ABC in server/detectors/base.py. The two concrete implementations are in server/detectors/face_bisenet.py and server/detectors/yolov8_seg.py. Import threading in base.py."
    },
    {
      "id": "US-002",
      "title": "Wrap json.loads in try-except in ws_inpaint",
      "priority": 2,
      "passes": true,
      "description": "The ws_inpaint WebSocket handler at server/app.py:204 calls json.loads(msg) without a try-except. Malformed JSON from the client will crash the handler and kill the WebSocket connection. Wrap it in a try-except that sends an error message back and continues the loop.",
      "acceptanceCriteria": [
        "json.loads(msg) at app.py:204 is wrapped in try-except json.JSONDecodeError",
        "On JSONDecodeError, send JSON error message back: {\"error\": \"Invalid JSON\"} and continue",
        "The while True loop continues after the error (does not break or re-raise)",
        "Quality check: python -m py_compile server/app.py"
      ],
      "notes": "The exact line is app.py:204 (req = json.loads(msg)). Catch json.JSONDecodeError specifically, not bare Exception. Send the error via ws.send_text(json.dumps({...})). Use 'continue' to skip to the next message."
    },
    {
      "id": "US-003",
      "title": "Add try-except in detection while loop",
      "priority": 3,
      "passes": true,
      "description": "The detection WebSocket handler ws_detect has a while True loop (app.py:165-193) where a single bad frame or detection error kills the entire connection. Add a try-except inside the loop body so that per-frame errors are logged and the loop continues.",
      "acceptanceCriteria": [
        "The body of the while True loop in ws_detect (app.py:165-193) is wrapped in try-except Exception",
        "Exceptions are logged with logger.exception() or logger.error()",
        "The loop continues after an error (does not break or close the WebSocket)",
        "WebSocketDisconnect is NOT caught by the inner try-except (it must propagate to the outer handler)",
        "Quality check: python -m py_compile server/app.py"
      ],
      "notes": "The outer try/except WebSocketDisconnect at app.py:164,194-195 must remain unchanged. The new try-except goes INSIDE the while loop, wrapping lines 167-193. Be careful: WebSocketDisconnect is raised by ws.receive_bytes() and must NOT be caught by the inner handler. In Starlette, WebSocketDisconnect does NOT inherit from Exception, so catching Exception is sufficient to avoid catching disconnects."
    },
    {
      "id": "US-004",
      "title": "Protect inpaint state with lock",
      "priority": 4,
      "passes": true,
      "description": "inpaint_status, inpaint_status_detail, and inpaint_engine are read and written from multiple threads without synchronization. Use state.lock consistently for all access to these fields.",
      "acceptanceCriteria": [
        "In _load_inpaint_model(): all writes to state.inpaint_status, state.inpaint_status_detail, and state.inpaint_engine are inside 'with state.lock:' blocks",
        "In api_status(): reads of state.inpaint_status and state.inpaint_status_detail are inside 'with state.lock:'",
        "In ws_inpaint(): the check of state.inpaint_engine (app.py:207,217) is inside 'with state.lock:'",
        "The on_status callback inside _load_inpaint_model also uses the lock",
        "Quality check: python -m py_compile server/app.py"
      ],
      "notes": "state.lock already exists and is used for frame/mask access. Reuse it for inpaint state — do NOT create a new lock. The _load_inpaint_model function runs in a background thread (threading.Thread). The on_status callback at app.py:45-47 writes status from that thread. api_status at app.py:342-348 reads from the async event loop thread. ws_inpaint reads inpaint_engine at app.py:207 and 217. Keep lock scopes narrow — don't hold the lock during long operations like model loading or inference."
    },
    {
      "id": "US-005",
      "title": "Extract InpaintOrchestrator class",
      "priority": 5,
      "passes": true,
      "description": "Extract the inpainting generation lifecycle (request validation, async task orchestration, progress streaming, cancellation) from ws_inpaint into a dedicated InpaintOrchestrator class. The WebSocket handler should become ~30 lines of message dispatch.",
      "acceptanceCriteria": [
        "New class InpaintOrchestrator exists (either in server/app.py or a new server/inpaint_orchestrator.py)",
        "InpaintOrchestrator encapsulates: input validation, generation lifecycle, progress streaming, cancel handling",
        "ws_inpaint handler is reduced to message dispatch (~30-50 lines max)",
        "All existing functionality preserved: progress updates, cancel mid-generation, error messages, result encoding",
        "Lock patterns from US-004 are preserved in the refactored code",
        "Quality check: python -m py_compile server/app.py"
      ],
      "notes": "This is the largest refactor. The current ws_inpaint spans app.py:198-338 (139 lines). Key complexity: the asyncio.wait() loop that multiplexes gen_task, ws_recv, and progress_get futures. The cancel flow sets state.inpaint_engine.cancel() which raises GenerationCancelled in the executor thread. The progress callback uses loop.call_soon_threadsafe to push to an asyncio.Queue. All of these patterns must be preserved. Do NOT change the WebSocket message format — the frontend expects exact JSON keys (status, step, total_steps, elapsed, image, error). Ensure the lock from US-004 is preserved."
    },
    {
      "id": "US-006",
      "title": "Introduce DetectionMode and ModelStatus enums",
      "priority": 6,
      "passes": true,
      "description": "Replace magic strings for detection modes ('face', 'object') and model statuses ('loading', 'ready', 'error', etc.) with Python enums. Create a new server/enums.py module and update all references.",
      "acceptanceCriteria": [
        "New file server/enums.py exists with DetectionMode enum (FACE='face', OBJECT='object') and ModelStatus enum (LOADING='loading', READY='ready', ERROR='error')",
        "All bare string comparisons for mode in app.py use DetectionMode enum values",
        "All bare string assignments/comparisons for inpaint_status use ModelStatus enum values",
        "config.py DEFAULT_DETECTION_MODE uses or is compatible with DetectionMode",
        "Enum .value is used when serializing to JSON (frontend expects the string values)",
        "Quality check: python -m py_compile server/enums.py && python -m py_compile server/app.py && python -m py_compile server/config.py"
      ],
      "notes": "Use Python's enum.Enum with string values so .value gives the JSON-serializable string. The frontend sends and expects these exact strings, so the enum values must match. In app.py, mode comparisons happen at: get_detector_sync (lines 76,88,103), _parse_detect_params (line 136). Status assignments happen at: _load_inpaint_model (lines 46,57,60), AppState default (line 36). Status reads happen at: api_status (line 347). Be careful with JSON serialization — use .value when building response dicts."
    },
    {
      "id": "US-007",
      "title": "Prune vendored YOLOv5 code",
      "priority": 7,
      "passes": true,
      "description": "The utils/ and models/ directories contain the full vendored YOLOv5 codebase (~250KB), but only a few functions are used: letterbox, check_img_size, non_max_suppression_face, scale_coords, plus attempt_load from models. Extract the used functions into server/yolov5_compat.py, update server/detection.py imports, and delete the vendored directories.",
      "acceptanceCriteria": [
        "New file server/yolov5_compat.py exists with the extracted functions",
        "server/detection.py imports from server.yolov5_compat instead of utils.* and models.*",
        "The utils/ directory is deleted (git rm -rf utils/)",
        "The models/ directory is deleted (git rm -rf models/)",
        "server/detection.py no longer manipulates sys.path",
        "Quality check: python -m py_compile server/yolov5_compat.py && python -m py_compile server/detection.py"
      ],
      "notes": "THIS IS THE HIGHEST RISK STORY. Key gotcha: the model weights file is a serialized PyTorch checkpoint. attempt_load() from models/experimental.py deserializes it, which may require the model class definitions from models/yolo.py and models/common.py to be available during unpickling. You MUST either: (a) keep attempt_load and its model class dependencies in yolov5_compat.py, or (b) use weights_only=True if the weights format supports it, or (c) keep the model architecture classes available. Investigate what attempt_load actually does before deleting models/. The functions from utils/ are pure numpy/torch utilities and are safe to extract. Also check if face_bisenet.py or any other file imports from utils/ or models/ — detection.py is the main consumer but there may be others. If py_compile fails, the story fails — do not force it."
    }
  ]
}
